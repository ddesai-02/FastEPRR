import os
import glob
import subprocess
from collections import defaultdict

# --- Configuration ---
# Directory containing your trimmed FASTQ files
trimmed_dir = "/home/devan/projects/def-shaferab/devan/Odocoileus_virginianus/fasteprr/trimmed"

# Directory where the final merged files and merge job scripts will be saved
merge_output_dir = os.path.join(trimmed_dir, "merged")

os.makedirs(merge_output_dir, exist_ok=True)
print(f"Trimmed directory: {trimmed_dir}")
print(f"Merge output directory: {merge_output_dir}")
print("-" * 30)

# Dictionary to hold lists of R1 and R2 files grouped by Sample ID
# Key: 'SampleID' (e.g., 'Odo_Key3')
# Value: {'R1': [list of R1 files], 'R2': [list of R2 files]}
sample_groups = defaultdict(lambda: {'R1': [], 'R2': []})

# --- Step 1: Group Files by Sample ID ---
all_trimmed_files = glob.glob(os.path.join(trimmed_dir, "*_trimmed_R?.fastq.gz"))

for filepath in all_trimmed_files:
    filename = os.path.basename(filepath)
    
    # 1. Determine the Read Group (R1 or R2)
    if '_R1.fastq.gz' in filename:
        read_group = 'R1'
    elif '_R2.fastq.gz' in filename:
        read_group = 'R2'
    else:
        continue # Skip files that aren't R1 or R2

    # 2. Extract the Sample ID (Everything before the first '_S')
    # Use regex or simple split, but since your files start with the ID,
    # let's find the first _S and take everything before it.
    
    # Find the part that looks like '_SXX' or '_SXXX'
    parts = filename.split('_S')
    if len(parts) > 1:
        # The Sample ID is the first part (e.g., 'Odo_Key3')
        sample_id = parts[0]
    else:
        # Handle cases that might not fit the pattern perfectly (e.g., files already merged)
        print(f"⚠️ Skipping file with unusual naming: {filename}")
        continue
        
    # 3. Add the full path to the correct group
    sample_groups[sample_id][read_group].append(filepath)

# --- Step 2: Generate and Submit Merge Jobs for Multi-Lane Samples ---
submitted_jobs = 0

for sample_id, files in sample_groups.items():
    # A sample needs merging if it has files from more than one lane (i.e., > 1 file in R1/R2 list)
    if len(files['R1']) > 1 or len(files['R2']) > 1:
        
        # NOTE: We assume len(R1) == len(R2), as they are paired-end
        
        # Create a list of files to concatenate, ensuring the R1 and R2 lists are in the SAME order
        # We sort them by full path (or filename) to ensure R1 order matches R2 order
        r1_files_sorted = sorted(files['R1'])
        r2_files_sorted = sorted(files['R2'])
        
        # Create the input string for the 'cat' command
        r1_input_str = " ".join(r1_files_sorted)
        r2_input_str = " ".join(r2_files_sorted)
        
        # Define final output names
        final_r1 = os.path.join(merge_output_dir, f"{sample_id}_merged_R1.fastq.gz")
        final_r2 = os.path.join(merge_output_dir, f"{sample_id}_merged_R2.fastq.gz")
        
        # --- Generate SBATCH script for merging ---
        merge_job_script = f"{sample_id}_merge_job.sh"
        
        script_content = f"""#!/bin/bash
#SBATCH --account=rrg-shaferab
#SBATCH --mem=2G
#SBATCH --cpus-per-task=1
#SBATCH --time=0:30:00
#SBATCH --job-name=merge_{sample_id}
#SBATCH --output={merge_output_dir}/merge_{sample_id}.out
#SBATCH --error={merge_output_dir}/merge_{sample_id}.err

# NOTE: The 'cat' command is highly optimized for this.
# It is CRITICAL that the R1 and R2 files are concatenated in the exact same order!

echo "Starting merge for {sample_id}..."
echo "Merging R1 files: {r1_input_str}"
cat {r1_input_str} > {final_r1}

echo "Merging R2 files: {r2_input_str}"
cat {r2_input_str} > {final_r2}

if [ $? -eq 0 ]; then
    echo "✅ Merge complete for {sample_id}."
else
    echo "❌ Merge FAILED for {sample_id}."
fi
"""
        with open(merge_job_script, "w") as f:
            f.write(script_content)
        
        # --- Submit the merge job ---
        try:
            subprocess.run(["sbatch", merge_job_script], check=True, text=True, capture_output=True)
            print(f"➡️ Submitted MERGE job for multi-lane sample: {sample_id}")
            submitted_jobs += 1
        except subprocess.CalledProcessError as e:
            print(f"❌ Error submitting MERGE job for {sample_id}. SBATCH failed.")
            print(f"Stderr: {e.stderr}")
            print(f"Stdout: {e.stdout}")
    
    else:
        # Optional: You can move the single-lane files to the merged directory here
        print(f"✅ Single-lane sample: {sample_id}. No merge needed.")
        
print("-" * 30)
print(f"Total multi-lane samples submitted for merging: {submitted_jobs}")
